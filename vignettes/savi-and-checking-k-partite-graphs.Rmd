---
title: "Savi and Multipartite Graphs"
author: "Nick Simone"
date: "Last Modified: `r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Savi and Multipartite Graphs}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

------
Abstract:
   The main problem we look at in this vignette is determining if a graph is $k$-partite.  We use this problem to test the performance of the greedy algorithm versus different cooling schedules of simulated annealing.  Determining if a graph is $k$-partite when $k>2$ is a difficult optimization problem, so it is a good test for running annealing.
  Please note that throughout this vignette we have set the seed in each code block that contains random elements.  This allows to you run each code block seperately and get the same results as we have below and in the associated thesis. 
------

## 1) Defining the Problem
A $k$-partite graph $G$ is one whose vertex set can be partitioned into $k$ subsets, or parts, in such a way that no edge has both ends in the same part (from Bondy, Murty).  To determine if a graph is $k$-partite, we will attempt to minimize the number of edges between vertices of the same group.

## 2) The Scoring Function
The following function returns the number of edges between vertices in the same group.  Thus, if the score is zero, then we have found a state where the graph is $k$-partite.  Since such a state exists, we have shown that the graph itself is $k$-partite.

```{r, message=FALSE}
library(savi)

myScoringFunction<-function(g){
  #Get the number of Groups
  numOfGroups<-max(V(g)$group)

  #Count the number of inter-group edges
  s<-0
  for(i in c(1:numOfGroups)){
    s<-s+length(which(tail_of(g,E(g))$group==i & head_of(g,E(g))$group==i))
  }

  return(s)
}
```

## 3)  Known Example
It is a good idea to run simulated annealing on a graph with a known optimal score first.  The following graph is 3-partite.  We can use this to look at the behavior of the greedy algorithm and the adaptive cooling schedule.  

```{r, message=FALSE}
adjm<-matrix(c(0,0,1,1,1,1,
               0,0,1,1,1,1,
               1,1,0,0,1,1,
               1,1,0,0,1,1,
               1,1,1,1,0,0,
               1,1,1,1,0,0),
             nrow=6,
             ncol=6,
             byrow = TRUE)

g=graph_from_adjacency_matrix(adjm, mode=c("undirected"))
V(g)$group=c(1,2,3,1,2,3)

set.seed(142)
results_Greedy<-runSavi(g,3,"Greedy",1000,myScoringFunction)
plot(results_Greedy$scoreArr)
```

As you can see from the plot, the minimum score found is 0.  If you have trouble reading the graph, the minimum score can be found in the "resultList" variable returned by runSavi.  We can visualize the minimum state found by coloring the vertices according to what group they are in.  Note that the graph below is colored with three colors and no two vertices of the same color are adjacent.

```{r, fig.height = 4, fig.width = 6, fig.align='center'}
plotWithGroups(results_Greedy$minGraph,3)
```

We now look at the behavior of simulated annealing with the adaptive cooling schedule.  Again, the minimum score found is 0.  Note that the score fluctuates up and down as there is always a chance that the algorithm decides to move to a higher score.  Because of this, there is a chance the lowest score may not be the one we end on.  However, savi keeps track of the minimum score so you can find it in the "resultList" variable after runSavi finishes.  

```{r, fig.height = 4, fig.width = 6, fig.align='center'}
set.seed(142)
results_Adaptive<-runSavi(g,3,"Adaptive",c(500,10,20,0.8,0),myScoringFunction)
plot(results_Adaptive$scoreArr)
```

## 4) Greedy Algorithm Failure Example
One of the main motivations for using simulated annealing over the greedy algorithm is the existence of strict local minimum states.  These are states that do not produce the optimal score, but every state within one step of it has a higher score.  When the greedy algorithm moves to a such a state, it will not progress any further.  However, the annealing process has some probability of moving to a state with a higher score, so the process can move away from it.  A more in depth discussion is in the associated thesis.

Below is the code that produces Figure 6.4b in the associated thesis.  The graph is in a strict local minimum state.  Because of this, the greedy algorithm fails to find the optimal score, but the annealing process is successful.  

```{r fig.height = 4, fig.width = 6, fig.align='center'}
adjm<-matrix(c(0,1,0,0,1,0,0,0,0,0,
               1,0,0,0,1,0,0,0,0,0,
               0,0,0,1,1,0,0,0,0,0,
               0,0,1,0,1,0,0,0,0,0,
               1,1,1,1,0,1,0,0,0,0,
               0,0,0,0,1,0,1,1,1,1,
               0,0,0,0,0,1,0,1,0,0,
               0,0,0,0,0,1,1,0,0,0,
               0,0,0,0,0,1,0,0,0,1,
               0,0,0,0,0,1,0,0,1,0,
               0,0,0,0,0,1,0,0,1,0),
             nrow=10,
             ncol=10,
             byrow = TRUE)
g=graph_from_adjacency_matrix(adjm, mode=c("undirected"))
V(g)$group=c(1,2,1,2,3,3,1,2,1,2)

plotWithGroups(g,3)
```

We now run the greedy algorithm on this graph.  Observe that the score remains at 1.  Note that this code produces Plot 6.5 in the associated thesis.

```{r fig.height = 3, fig.width = 6, fig.align='center'}
set.seed(142)
results_Greedy<-runSavi(g,3,"Greedy",500,myScoringFunction)
plot(results_Greedy$scoreArr)
```

Next, we run simulated annealing with the adaptive cooling schedule.  Here, the true optimal score of 0 is found.  Thus, we have also shown that the above graph is 3-partite.  Note that this code produces Plot 6.6 in the associated thesis.

```{r fig.height = 3, fig.width = 6, fig.align='center'}
set.seed(142)
results_Adaptive<-runSavi(g,3,"Adaptive",c(500,10,10,0.8,0),myScoringFunction)
plot(results_Adaptive$scoreArr)
```

## 5) Large Example
We now consider a graph made of 50 vertices and want to see if it is 7-partite.  This graph is stored in the "SEVEN_PARTITE_EXAMPLE" data variable.  For this example, we run the greedy algorithm and simulated annealing with three different cooling schedules.  It should be noted that each block of code takes a long time to run.  

The following produces Plot 6.11 in the associated thesis.
```{r, message=FALSE, fig.height = 3, fig.width = 7, eval=FALSE}
#Greedy
set.seed(142)
results_Greedy<-runSavi(SEVEN_PARTITE_EXAMPLE,7,"Greedy",10000,myScoringFunction)
plot(results_Greedy$scoreArr)
```

```{r, message=FALSE, fig.height = 3, fig.width = 7, eval=FALSE}
#Log
set.seed(142)
results_Log<-runSavi(SEVEN_PARTITE_EXAMPLE,7,"Log",c(10000,1000,1),myScoringFunction)
plot(results_Log$scoreArr)
```

```{r, message=FALSE, fig.height = 3, fig.width = 7, eval=FALSE}
#Step
set.seed(142)
results_LongStep<-runSavi(SEVEN_PARTITE_EXAMPLE,7,"Step",c(10000,1000,100,0.8),myScoringFunction)
plot(results_LongStep$scoreArr)
```

The following produces Plot 6.12 in the associated thesis.
```{r, message=FALSE, fig.height = 3, fig.width = 7, eval=FALSE}
#Adaptive
set.seed(142)
results_Adaptive<-runSavi(SEVEN_PARTITE_EXAMPLE,7,"Adaptive",c(10000,1000,100,0.8,0),myScoringFunction)
plot(results_Adaptive$scoreArr)
```

